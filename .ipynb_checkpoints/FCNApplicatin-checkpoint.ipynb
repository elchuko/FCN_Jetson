{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import h5py\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten, Dense\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    dataset_path = glob.glob('./Dataset/training/image_2/*.png')\n",
    "    ground_truth = glob.glob('./Dataset/training/gt_image_2/*.png')\n",
    "    #print(dataset_path)\n",
    "    #print(ground_truth)\n",
    "    #labels = [0 if 'textbox' in addr else 1 for addr in dataset_path]\n",
    "    #images = cv.imread(dataset_path)\n",
    "    \n",
    "    compressed=list(zip(dataset_path, ground_truth))\n",
    "    #shuffle(compressed)\n",
    "    addrs, labels = zip(*compressed)\n",
    "    \n",
    "    train_addrs = addrs[0:int(0.6*len(addrs))]\n",
    "    train_labels = labels[0:int(0.6*len(labels))]\n",
    "    test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "    test_labels = labels[int(0.8*len(labels)):]\n",
    "    \n",
    "    train_x_l = len(train_addrs)\n",
    "    train_y_l = len(train_labels)\n",
    "    test_x_l = len(test_addrs)\n",
    "    test_y_l = len(test_labels)\n",
    "    \n",
    "    train_shape = (train_x_l,  256, 256, 3)\n",
    "    train_output_shape = (train_y_l, 256, 256, 3)\n",
    "    test_shape = (test_x_l,  256, 256, 3) #375,1242\n",
    "    test_output_shape = (test_y_l, 256, 256, 3)\n",
    "    \n",
    "    # Abrir un archivo HDF5 en modo escritura y crear los datasets\n",
    "    hdf5_file = h5py.File('./Dataset/pictures_dataset.h5', mode='w')\n",
    "    hdf5_file.create_dataset(\"train_img\", train_shape, np.int8)\n",
    "    hdf5_file.create_dataset(\"test_img\", test_shape, np.int8)\n",
    "    hdf5_file.create_dataset(\"train_mean\", train_shape[1:], np.float32)\n",
    "\n",
    "    hdf5_file.create_dataset(\"train_labels\", train_output_shape, np.int8)        \n",
    "    hdf5_file.create_dataset(\"test_labels\", test_output_shape, np.int8)\n",
    "    \n",
    "    #LoadImages\n",
    "    #hdf5_file[\"train_labels\"][...] = train_labels\n",
    "    #hdf5_file[\"test_labels\"][...] = test_labels\n",
    "\n",
    "    train_shape=hdf5_file[\"train_img\"].shape\n",
    "    mean = np.zeros(train_shape[1:], np.float32)\n",
    "    \n",
    "    #Training addresses\n",
    "    for i in range(len(train_addrs)):\n",
    "        addr = train_addrs[i]\n",
    "        img = cv.imread(addr)\n",
    "        img = cv.resize(img, (256, 256), interpolation=cv.INTER_NEAREST)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        hdf5_file[\"train_img\"][i, ...] = img[None]\n",
    "        #mean += img / float(len(train_labels))\n",
    "    \n",
    "    #Training output addresses\n",
    "    for i in range(len(train_labels)):\n",
    "        addr = train_labels[i]\n",
    "        img = cv.imread(addr)\n",
    "        img = cv.resize(img, (256, 256), interpolation=cv.INTER_NEAREST)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        hdf5_file[\"train_labels\"][i, ...] = img[None]\n",
    "        #mean += img / float(len(train_labels))\n",
    "    \n",
    "    #Testing addresses\n",
    "    for i in range(len(test_addrs)):\n",
    "        addr = test_addrs[i]\n",
    "        img = cv.imread(addr)\n",
    "        img = cv.resize(img, (256, 256), interpolation=cv.INTER_NEAREST)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        hdf5_file[\"test_img\"][i, ...] = img[None]\n",
    "    \n",
    "    #Testing output addresses\n",
    "    for i in range(len(test_labels)):\n",
    "        addr = test_labels[i]\n",
    "        img = cv.imread(addr)\n",
    "        img = cv.resize(img, (256, 256), interpolation=cv.INTER_NEAREST)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        hdf5_file[\"test_labels\"][i, ...] = img[None]\n",
    "        #mean += img / float(len(train_labels))\n",
    "    \n",
    "    #hdf5_file[\"train_mean\"][...] = mean\n",
    "    hdf5_file.close()\n",
    "    \n",
    "create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataset():\n",
    "    batch_size = 30\n",
    "    batch_n = 10\n",
    "    # Abrir el archivo HDF5, modo lectura\n",
    "    hdf5_file = h5py.File('./Dataset/pictures_dataset.h5', \"r\")\n",
    "    \n",
    "    # Determinar la longitud del dataset de entrenamiento\n",
    "    data_num = hdf5_file[\"train_img\"].shape[0]\n",
    "    test_num = hdf5_file[\"test_img\"].shape[0]\n",
    "    \n",
    "    # Crear una lista de lotes para barajear los datos\n",
    "    batches_list = list(range(int(ceil(float(data_num) / batch_size))))\n",
    "    shuffle(batches_list)\n",
    "    \n",
    "    training_list = list(range(int(ceil(float(test_num) / batch_size))))\n",
    "\n",
    "    # Recorramos los lotes\n",
    "    for n, i in enumerate(batches_list):\n",
    "        i_s = i * batch_size  # Indice de la primer imagen en este lote\n",
    "        i_e = min([(i + 1) * batch_size, data_num])  # Indice de la última imagen en este lote\n",
    "\n",
    "        # Leer las imágenes del lote\n",
    "        training_images = hdf5_file[\"train_img\"][i_s:i_e]\n",
    "        \n",
    "        # Leer etiquetas\n",
    "        training_labels = hdf5_file[\"train_labels\"][i_s:i_e]\n",
    "        \n",
    "        #print (n+1, '/', len(batches_list))\n",
    "        #print (f\"Etiqueta: {training_labels[0]}\")\n",
    "    \n",
    "        plt.imshow(training_images[0])\n",
    "        plt.imshow(training_labels[0])\n",
    "        plt.show()   \n",
    "        if n == (batch_n-1):  # finalizar despues de batch_num-1 lotes\n",
    "            break\n",
    "    for n, i in enumerate(training_list):\n",
    "        i_s = i * batch_size  # Indice de la primer imagen en este lote\n",
    "        i_e = min([(i + 1) * batch_size, test_num])  # Indice de la última imagen en este lote\n",
    "\n",
    "        # Leer las imágenes del lote\n",
    "        test_images = hdf5_file[\"test_img\"][i_s:i_e]\n",
    "        \n",
    "        # Leer etiquetas\n",
    "        test_labels = hdf5_file[\"test_labels\"][i_s:i_e]\n",
    "        \n",
    "        print (n+1, '/', len(batches_list))\n",
    "        print (f\"Etiqueta: {test_labels[0]}\")\n",
    "    \n",
    "        plt.imshow(test_images[0])\n",
    "        plt.show()   \n",
    "        if n == (batch_n-1):  # finalizar despues de batch_num-1 lotes\n",
    "            break\n",
    "    hdf5_file.close()\n",
    "    return (training_images, training_labels), (test_images, test_labels)\n",
    "\n",
    "var = extract_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_from_route():\n",
    "    (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "    training_set = (train_images, train_labels)\n",
    "    test_set = (test_images, test_labels)\n",
    "    return training_set, test_set\n",
    "\n",
    "training_set, test_set = load_dataset_from_route()\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "training_images = training_set[0]/255\n",
    "training_labels = training_set[1]\n",
    "test_images = test_set[0]/255\n",
    "test_labels = test_set[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(classes):\n",
    "    #model = vgg16.VGG16(include_top=True, weights=None, input_tensor=None, input_shape=(32,32,3), pooling='max', classes=10)\n",
    "    #sequential doesn't seem to work that well because \n",
    "    input_shape = (32,32,3)\n",
    "    #fcn_model = Sequential()\n",
    "    img_input = layers.Input(shape=input_shape)\n",
    "    \n",
    "    #primer bloque Conv -> Conv -> Pooling\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "    \n",
    "    #segundo bloque\n",
    "    x = layers.Conv2D(128, (3, 3),activation='relu',padding='same',name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),activation='relu',padding='same',name='block2_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    \n",
    "    #tercer bloque\n",
    "    x = layers.Conv2D(256, (3, 3),activation='relu',padding='same',name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),activation='relu',padding='same',name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),activation='relu',padding='same',name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    \n",
    "    pool_3 = x\n",
    "    \n",
    "    #cuarto bloque\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    \n",
    "    pool_4 = x\n",
    "    \n",
    "    #5to bloque\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    #Fullyconnected Layer\n",
    "    #x = layers.Flatten(name='flatten')(x)\n",
    "    #x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "    #x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
    "    #x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    #fc_6\n",
    "    x = layers.Conv2D(4096, 7, padding='valid', activation='relu', use_bias=True, name='fc_1')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    #fc_7\n",
    "    x = Conv2D(4096, 1, padding='valid', activation='relu', use_bias=True, name='fc_2')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    encoder_graph = Conv2D(classes, 1, padding='valid', activation='relu', use_bias=True, name='encoder_graph')(x)\n",
    "\n",
    "    # Unpool to 16x\n",
    "    score_2 = layers.Conv2DTranspose(classes, 4, strides=(2, 2), padding='valid')(encoder_graph)\n",
    "    score_pool_4 = layers.Conv2D(classes, 1, padding='valid', use_bias=True)(pool_4)\n",
    "    score_pool_4 = layers.Cropping2D(cropping=5)(score_pool_4)\n",
    "    score_16x_upsampled = Add()([score_2, score_pool_4])\n",
    "        \n",
    "    # Unpool to 8x\n",
    "    score_4 = layers.Conv2DTranspose(classes, 4, strides=(2, 2), padding='valid')(score_16x_upsampled)\n",
    "    score_pool_3 = layers.Conv2D(classes, 1, padding='valid', use_bias=True)(pool_3)\n",
    "    score_4 = layers.ZeroPadding2D(padding=((1,0), (1, 0)))(score_4)\n",
    "    score_pool_3 = layers.Cropping2D(cropping=9)(score_pool_3)\n",
    "    score_8x_upsampled = Add()([score_4, score_pool_3])\n",
    "\n",
    "    # Unpool to image shape\n",
    "    upsample = layers.Conv2DTranspose(classes, 16, strides=(8, 8), padding='same')(score_8x_upsampled)        \n",
    "    upsample = layers.Cropping2D(cropping=28)(upsample)\n",
    "    \n",
    "    output_graph = Activation('softmax')(upsample)\n",
    "\n",
    "#    print(output_graph.shape)\n",
    "    \n",
    "    #return output_graph\n",
    "    \n",
    "    #fcn_model = models.Model(img_input, x, name=\"FCN\")\n",
    "    return output_graph\n",
    "\n",
    "vgg_model = create_model(10)\n",
    "vgg_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse'])\n",
    "vgg_model.summary()\n",
    "vgg_model.fit(x=training_images, y=to_categorical(training_labels),batch_size = 32, epochs = 10, verbose = 1,callbacks = None, validation_split=0.0, validation_data=(test_images,to_categorical(test_labels)) )\n",
    "vgg_model.save_weights('modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('ElAvion.jpg')\n",
    "image = cv.resize(image, (32,32))\n",
    "plt.imshow(image)\n",
    "image = np.resize(image, (1,32,32,3))\n",
    "#plt.imshow(image)\n",
    "image = tf.cast(image, tf.float32)\n",
    "print(image.shape)\n",
    "prediction = vgg_model.predict(image, batch_size = None, verbose = 0, steps = None, callbacks = None, max_queue_size = 10, workers = 1, use_multiprocessing = False)\n",
    "print(prediction)\n",
    "#predicted = np.argmax(prediction.shape[0], axis=1)\n",
    "#print(class_names[predicted])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
