{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import h5py\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten, Dense, Dropout, Add, Activation\n",
    "from math import ceil\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    dataset_path = glob.glob('./Dataset/training/image_2/*.png')\n",
    "    ground_truth = glob.glob('./Dataset/training/gt_image_2/*.png')\n",
    "    #print(dataset_path)\n",
    "    #print(ground_truth)\n",
    "    #labels = [0 if 'textbox' in addr else 1 for addr in dataset_path]\n",
    "    #images = cv.imread(dataset_path)\n",
    "    \n",
    "    compressed=list(zip(dataset_path, ground_truth))\n",
    "    #shuffle(compressed)\n",
    "    addrs, labels = zip(*compressed)\n",
    "    \n",
    "    train_addrs = addrs[0:int(0.6*len(addrs))]\n",
    "    train_labels = labels[0:int(0.6*len(labels))]\n",
    "    test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "    test_labels = labels[int(0.8*len(labels)):]\n",
    "    \n",
    "    train_x_l = len(train_addrs)\n",
    "    train_y_l = len(train_labels)\n",
    "    test_x_l = len(test_addrs)\n",
    "    test_y_l = len(test_labels)\n",
    "    \n",
    "    train_shape = (train_x_l,  256, 256, 3)\n",
    "    train_output_shape = (train_y_l, 256, 256, 3)\n",
    "    test_shape = (test_x_l,  256, 256, 3) #375,1242\n",
    "    test_output_shape = (test_y_l, 256, 256, 3)\n",
    "    \n",
    "    # Abrir un archivo HDF5 en modo escritura y crear los datasets\n",
    "    hdf5_file = h5py.File('./Dataset/pictures_dataset.h5', mode='w')\n",
    "    hdf5_file.create_dataset(\"train_img\", train_shape, np.int8)\n",
    "    hdf5_file.create_dataset(\"test_img\", test_shape, np.int8)\n",
    "    hdf5_file.create_dataset(\"train_mean\", train_shape[1:], np.float32)\n",
    "\n",
    "    hdf5_file.create_dataset(\"train_labels\", train_output_shape, np.int8)        \n",
    "    hdf5_file.create_dataset(\"test_labels\", test_output_shape, np.int8)\n",
    "    \n",
    "    #LoadImages\n",
    "    #hdf5_file[\"train_labels\"][...] = train_labels\n",
    "    #hdf5_file[\"test_labels\"][...] = test_labels\n",
    "\n",
    "    train_shape=hdf5_file[\"train_img\"].shape\n",
    "    mean = np.zeros(train_shape[1:], np.float32)\n",
    "    \n",
    "    #Training addresses\n",
    "    for i in range(len(train_addrs)):\n",
    "        addr = train_addrs[i]\n",
    "        img = cv.imread(addr)\n",
    "        img = cv.resize(img, (256, 256), interpolation=cv.INTER_NEAREST)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        hdf5_file[\"train_img\"][i, ...] = img[None]\n",
    "        #mean += img / float(len(train_labels))\n",
    "    \n",
    "    #Training output addresses\n",
    "    for i in range(len(train_labels)):\n",
    "        addr = train_labels[i]\n",
    "        img = cv.imread(addr)\n",
    "        img = cv.resize(img, (256, 256), interpolation=cv.INTER_NEAREST)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        hdf5_file[\"train_labels\"][i, ...] = img[None]\n",
    "        #mean += img / float(len(train_labels))\n",
    "    \n",
    "    #Testing addresses\n",
    "    for i in range(len(test_addrs)):\n",
    "        addr = test_addrs[i]\n",
    "        img = cv.imread(addr)\n",
    "        img = cv.resize(img, (256, 256), interpolation=cv.INTER_NEAREST)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        hdf5_file[\"test_img\"][i, ...] = img[None]\n",
    "    \n",
    "    #Testing output addresses\n",
    "    for i in range(len(test_labels)):\n",
    "        addr = test_labels[i]\n",
    "        img = cv.imread(addr)\n",
    "        img = cv.resize(img, (256, 256), interpolation=cv.INTER_NEAREST)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        hdf5_file[\"test_labels\"][i, ...] = img[None]\n",
    "        #mean += img / float(len(train_labels))\n",
    "    \n",
    "    #hdf5_file[\"train_mean\"][...] = mean\n",
    "    hdf5_file.close()\n",
    "    \n",
    "create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataset():\n",
    "    batch_size = 30\n",
    "    batch_n = 10\n",
    "    # Abrir el archivo HDF5, modo lectura\n",
    "    hdf5_file = h5py.File('./Dataset/pictures_dataset.h5', \"r\")\n",
    "    \n",
    "    # Determinar la longitud del dataset de entrenamiento\n",
    "    data_num = hdf5_file[\"train_img\"].shape[0]\n",
    "    test_num = hdf5_file[\"test_img\"].shape[0]\n",
    "    \n",
    "    # Crear una lista de lotes para barajear los datos\n",
    "    batches_list = list(range(int(ceil(float(data_num) / batch_size))))\n",
    "    shuffle(batches_list)\n",
    "    \n",
    "    training_list = list(range(int(ceil(float(test_num) / batch_size))))\n",
    "\n",
    "    # Recorramos los lotes\n",
    "    for n, i in enumerate(batches_list):\n",
    "        i_s = i * batch_size  # Indice de la primer imagen en este lote\n",
    "        i_e = min([(i + 1) * batch_size, data_num])  # Indice de la última imagen en este lote\n",
    "\n",
    "        # Leer las imágenes del lote\n",
    "        training_images = hdf5_file[\"train_img\"][i_s:i_e]\n",
    "        \n",
    "        # Leer etiquetas\n",
    "        training_labels = hdf5_file[\"train_labels\"][i_s:i_e]\n",
    "        \n",
    "        #print (n+1, '/', len(batches_list))\n",
    "        #print (f\"Etiqueta: {training_labels[0]}\")\n",
    "        '''\n",
    "        plt.imshow(training_images[0])\n",
    "        plt.show()\n",
    "        plt.imshow(training_labels[0])\n",
    "        plt.show()\n",
    "        '''\n",
    "        if n == (batch_n-1):  # finalizar despues de batch_num-1 lotes\n",
    "            break\n",
    "    for n, i in enumerate(training_list):\n",
    "        i_s = i * batch_size  # Indice de la primer imagen en este lote\n",
    "        i_e = min([(i + 1) * batch_size, test_num])  # Indice de la última imagen en este lote\n",
    "\n",
    "        # Leer las imágenes del lote\n",
    "        test_images = hdf5_file[\"test_img\"][i_s:i_e]\n",
    "        \n",
    "        # Leer etiquetas\n",
    "        test_labels = hdf5_file[\"test_labels\"][i_s:i_e]\n",
    "        \n",
    "        #print (n+1, '/', len(batches_list))\n",
    "        #print (f\"Etiqueta: {test_labels[0]}\")\n",
    "    \n",
    "        #plt.imshow(test_images[0])\n",
    "        #plt.show()   \n",
    "        if n == (batch_n-1):  # finalizar despues de batch_num-1 lotes\n",
    "            break\n",
    "    hdf5_file.close()\n",
    "    return (training_images, training_labels), (test_images, test_labels)\n",
    "\n",
    "var = extract_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_from_route():\n",
    "    #(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "    (train_images, train_labels),(test_images, test_labels) = extract_dataset()\n",
    "    training_set = (train_images, train_labels)\n",
    "    test_set = (test_images, test_labels)\n",
    "    return training_set, test_set\n",
    "\n",
    "training_set, test_set = load_dataset_from_route()\n",
    "#class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
    "training_images = training_set[0]/255\n",
    "training_labels = training_set[1]\n",
    "test_images = test_set[0]/255\n",
    "test_labels = test_set[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 14, 14, 2)\n",
      "(None, 14, 14, 2)\n",
      "(None, 56, 56, 2)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 32, 32, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 16, 16, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 16, 16, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 8, 8, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc_1 (Conv2D)                   (None, 2, 2, 4096)   102764544   block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 2, 2, 4096)   0           fc_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc_2 (Conv2D)                   (None, 2, 2, 4096)   16781312    dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 2, 2, 4096)   0           fc_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_graph (Conv2D)          (None, 2, 2, 2)      8194        dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 2)    1026        block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_33 (Conv2DTran (None, 6, 6, 2)      66          encoder_graph[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_33 (Cropping2D)      (None, 6, 6, 2)      0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 6, 6, 2)      0           conv2d_transpose_33[0][0]        \n",
      "                                                                 cropping2d_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 2)    514         block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_34 (Conv2DTran (None, 14, 14, 2)    66          add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_34 (Cropping2D)      (None, 14, 14, 2)    0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 14, 14, 2)    0           conv2d_transpose_34[0][0]        \n",
      "                                                                 cropping2d_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_35 (Conv2DTran (None, 112, 112, 2)  1026        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_35 (Cropping2D)      (None, 56, 56, 2)    0           conv2d_transpose_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 2)    0           cropping2d_35[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 134,271,436\n",
      "Trainable params: 134,271,436\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(30, 256, 256, 3)\n",
      "(30, 256, 256, 3)\n",
      "(28, 256, 256, 3)\n",
      "(28, 256, 256, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (30, 256, 256, 3) was passed for an output of shape (None, 56, 56, 2) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-777fbe3e98b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m \u001b[0mvgg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;31m#ValueError: A target array with shape (30, 256, 256, 3) was passed for an output of shape (None, 56, 56, 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;31m#while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[0;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2536\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2538\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2540\u001b[0m       \u001b[1;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    741\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[0;32m    742\u001b[0m                            \u001b[1;34m' was passed for an output of shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m                            \u001b[1;34m' while using as loss `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    744\u001b[0m                            \u001b[1;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                            'as the output.')\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (30, 256, 256, 3) was passed for an output of shape (None, 56, 56, 2) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "def create_model(classes):\n",
    "    #model = vgg16.VGG16(include_top=True, weights=None, input_tensor=None, input_shape=(32,32,3), pooling='max', classes=10)\n",
    "    #sequential doesn't seem to work that well because \n",
    "    input_shape = (256,256,3)\n",
    "    #fcn_model = Sequential()\n",
    "    img_input = layers.Input(shape=input_shape)\n",
    "    \n",
    "    #primer bloque Conv -> Conv -> Pooling\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "    \n",
    "    #segundo bloque\n",
    "    x = layers.Conv2D(128, (3, 3),activation='relu',padding='same',name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),activation='relu',padding='same',name='block2_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    \n",
    "    #tercer bloque\n",
    "    x = layers.Conv2D(256, (3, 3),activation='relu',padding='same',name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),activation='relu',padding='same',name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),activation='relu',padding='same',name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    \n",
    "    pool_3 = x\n",
    "    \n",
    "    #cuarto bloque\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    \n",
    "    pool_4 = x\n",
    "    \n",
    "    #5to bloque\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    #Fullyconnected Layer\n",
    "    #x = layers.Flatten(name='flatten')(x)\n",
    "    #x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "    #x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
    "    #x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    #fc_6\n",
    "    x = layers.Conv2D(4096, 7, padding='valid', activation='relu', use_bias=True, name='fc_1')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    #fc_7\n",
    "    x = Conv2D(4096, 1, padding='valid', activation='relu', use_bias=True, name='fc_2')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    encoder_graph = Conv2D(classes, 1, padding='valid', activation='relu', use_bias=True, name='encoder_graph')(x)\n",
    "\n",
    "    # Unpool to 16x\n",
    "    score_2 = layers.Conv2DTranspose(classes, 4, strides=(2, 2), padding='valid')(encoder_graph)\n",
    "    score_pool_4 = layers.Conv2D(classes, 1, padding='valid', use_bias=True)(pool_4)\n",
    "    score_pool_4 = layers.Cropping2D(cropping=5)(score_pool_4)\n",
    "    score_16x_upsampled = Add()([score_2, score_pool_4])\n",
    "        \n",
    "    # Unpool to 8x\n",
    "    score_4 = layers.Conv2DTranspose(classes, 4, strides=(2, 2), padding='valid')(score_16x_upsampled)\n",
    "    score_pool_3 = layers.Conv2D(classes, 1, padding='valid', use_bias=True)(pool_3)\n",
    "    #score_4 = layers.ZeroPadding2D(padding=((1,0), (1, 0)))(score_4)\n",
    "    print(score_4.shape)\n",
    "    score_pool_3 = layers.Cropping2D(cropping=9)(score_pool_3)\n",
    "    print(score_pool_3.shape)\n",
    "    score_8x_upsampled = Add()([score_4, score_pool_3])\n",
    "    #ValueError: Operands could not be broadcast together with shapes (15, 15, 2) (14, 14, 2)\n",
    "\n",
    "    # Unpool to image shape\n",
    "    upsample = layers.Conv2DTranspose(classes, 16, strides=(8, 8), padding='same')(score_8x_upsampled)        \n",
    "    upsample = layers.Cropping2D(cropping=28)(upsample)\n",
    "    \n",
    "    output_graph = Activation('softmax')(upsample)\n",
    "\n",
    "    #print(output_graph.shape)\n",
    "    \n",
    "    #return output_graph\n",
    "    \n",
    "    fcn_model = Model(img_input, output_graph)\n",
    "    return fcn_model\n",
    "\n",
    "vgg_model = create_model(2)\n",
    "vgg_model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['acc', 'mse'])\n",
    "vgg_model.summary()\n",
    "print(training_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "vgg_model.fit(x=training_images, y=training_labels,batch_size = 32, epochs = 10, verbose = 1,callbacks = None, validation_split=0.0, validation_data=(test_images,test_labels) )\n",
    "#ValueError: A target array with shape (30, 256, 256, 3) was passed for an output of shape (None, 56, 56, 2) \n",
    "#while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.\n",
    "#Esto se refiere a que output_graph es un arreglo con dimensiones (None, 56, 56,2)\n",
    "\n",
    "vgg_model.save_weights('modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('ElAvion.jpg')\n",
    "image = cv.resize(image, (32,32))\n",
    "plt.imshow(image)\n",
    "image = np.resize(image, (1,32,32,3))\n",
    "#plt.imshow(image)\n",
    "image = tf.cast(image, tf.float32)\n",
    "print(image.shape)\n",
    "prediction = vgg_model.predict(image, batch_size = None, verbose = 0, steps = None, callbacks = None, max_queue_size = 10, workers = 1, use_multiprocessing = False)\n",
    "print(prediction)\n",
    "#predicted = np.argmax(prediction.shape[0], axis=1)\n",
    "#print(class_names[predicted])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
