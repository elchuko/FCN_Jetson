{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import h5py\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten, Dense, Dropout, Add, Activation\n",
    "from math import ceil\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    dataset_path = glob.glob('./Dataset/training/image_2/*.png')\n",
    "    ground_truth = glob.glob('./Dataset/training/gt_image_2/*.png')\n",
    "    #print(dataset_path)\n",
    "    #print(ground_truth)\n",
    "    #labels = [0 if 'textbox' in addr else 1 for addr in dataset_path]\n",
    "    #images = cv.imread(dataset_path)\n",
    "    \n",
    "    compressed=list(zip(dataset_path, ground_truth))\n",
    "    #shuffle(compressed)\n",
    "    addrs, labels = zip(*compressed)\n",
    "    \n",
    "    train_addrs = addrs[0:int(0.6*len(addrs))]\n",
    "    train_labels = labels[0:int(0.6*len(labels))]\n",
    "    test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "    test_labels = labels[int(0.8*len(labels)):]\n",
    "    \n",
    "    train_x_l = len(train_addrs)\n",
    "    train_y_l = len(train_labels)\n",
    "    test_x_l = len(test_addrs)\n",
    "    test_y_l = len(test_labels)\n",
    "    \n",
    "    train_shape = (train_x_l,  256, 256, 3)\n",
    "    train_output_shape = (train_y_l, 256, 256, 3)\n",
    "    test_shape = (test_x_l,  256, 256, 3) #375,1242\n",
    "    test_output_shape = (test_y_l, 256, 256, 3)\n",
    "    \n",
    "    # Abrir un archivo HDF5 en modo escritura y crear los datasets\n",
    "    hdf5_file = h5py.File('./Dataset/pictures_dataset.h5', mode='w')\n",
    "    hdf5_file.create_dataset(\"train_img\", train_shape, np.int8)\n",
    "    hdf5_file.create_dataset(\"test_img\", test_shape, np.int8)\n",
    "    hdf5_file.create_dataset(\"train_mean\", train_shape[1:], np.float32)\n",
    "\n",
    "    hdf5_file.create_dataset(\"train_labels\", train_output_shape, np.int8)        \n",
    "    hdf5_file.create_dataset(\"test_labels\", test_output_shape, np.int8)\n",
    "    \n",
    "    #LoadImages\n",
    "    #hdf5_file[\"train_labels\"][...] = train_labels\n",
    "    #hdf5_file[\"test_labels\"][...] = test_labels\n",
    "\n",
    "    train_shape=hdf5_file[\"train_img\"].shape\n",
    "    mean = np.zeros(train_shape[1:], np.float32)\n",
    "    \n",
    "    #Training addresses\n",
    "    for i in range(len(train_addrs)):\n",
    "        addr = train_addrs[i]\n",
    "        img = cv.imread(addr)\n",
    "        img = cv.resize(img, (256, 256), interpolation=cv.INTER_NEAREST)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        hdf5_file[\"train_img\"][i, ...] = img[None]\n",
    "        #mean += img / float(len(train_labels))\n",
    "    \n",
    "    #Training output addresses\n",
    "    for i in range(len(train_labels)):\n",
    "        addr = train_labels[i]\n",
    "        img = cv.imread(addr)\n",
    "        img = cv.resize(img, (256, 256), interpolation=cv.INTER_NEAREST)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        hdf5_file[\"train_labels\"][i, ...] = img[None]\n",
    "        #mean += img / float(len(train_labels))\n",
    "    \n",
    "    #Testing addresses\n",
    "    for i in range(len(test_addrs)):\n",
    "        addr = test_addrs[i]\n",
    "        img = cv.imread(addr)\n",
    "        img = cv.resize(img, (256, 256), interpolation=cv.INTER_NEAREST)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        hdf5_file[\"test_img\"][i, ...] = img[None]\n",
    "    \n",
    "    #Testing output addresses\n",
    "    for i in range(len(test_labels)):\n",
    "        addr = test_labels[i]\n",
    "        img = cv.imread(addr)\n",
    "        img = cv.resize(img, (256, 256), interpolation=cv.INTER_NEAREST)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        hdf5_file[\"test_labels\"][i, ...] = img[None]\n",
    "        #mean += img / float(len(train_labels))\n",
    "    \n",
    "    #hdf5_file[\"train_mean\"][...] = mean\n",
    "    hdf5_file.close()\n",
    "    \n",
    "create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataset():\n",
    "    batch_size = 30\n",
    "    batch_n = 10\n",
    "    # Abrir el archivo HDF5, modo lectura\n",
    "    hdf5_file = h5py.File('./Dataset/pictures_dataset.h5', \"r\")\n",
    "    \n",
    "    # Determinar la longitud del dataset de entrenamiento\n",
    "    data_num = hdf5_file[\"train_img\"].shape[0]\n",
    "    test_num = hdf5_file[\"test_img\"].shape[0]\n",
    "    \n",
    "    # Crear una lista de lotes para barajear los datos\n",
    "    batches_list = list(range(int(ceil(float(data_num) / batch_size))))\n",
    "    shuffle(batches_list)\n",
    "    \n",
    "    training_list = list(range(int(ceil(float(test_num) / batch_size))))\n",
    "\n",
    "    # Recorramos los lotes\n",
    "    for n, i in enumerate(batches_list):\n",
    "        i_s = i * batch_size  # Indice de la primer imagen en este lote\n",
    "        i_e = min([(i + 1) * batch_size, data_num])  # Indice de la última imagen en este lote\n",
    "\n",
    "        # Leer las imágenes del lote\n",
    "        training_images = hdf5_file[\"train_img\"][i_s:i_e]\n",
    "        \n",
    "        # Leer etiquetas\n",
    "        training_labels = hdf5_file[\"train_labels\"][i_s:i_e]\n",
    "        \n",
    "        #print (n+1, '/', len(batches_list))\n",
    "        #print (f\"Etiqueta: {training_labels[0]}\")\n",
    "        '''\n",
    "        plt.imshow(training_images[0])\n",
    "        plt.show()\n",
    "        plt.imshow(training_labels[0])\n",
    "        plt.show()\n",
    "        '''\n",
    "        if n == (batch_n-1):  # finalizar despues de batch_num-1 lotes\n",
    "            break\n",
    "    for n, i in enumerate(training_list):\n",
    "        i_s = i * batch_size  # Indice de la primer imagen en este lote\n",
    "        i_e = min([(i + 1) * batch_size, test_num])  # Indice de la última imagen en este lote\n",
    "\n",
    "        # Leer las imágenes del lote\n",
    "        test_images = hdf5_file[\"test_img\"][i_s:i_e]\n",
    "        \n",
    "        # Leer etiquetas\n",
    "        test_labels = hdf5_file[\"test_labels\"][i_s:i_e]\n",
    "        \n",
    "        #print (n+1, '/', len(batches_list))\n",
    "        #print (f\"Etiqueta: {test_labels[0]}\")\n",
    "    \n",
    "        #plt.imshow(test_images[0])\n",
    "        #plt.show()   \n",
    "        if n == (batch_n-1):  # finalizar despues de batch_num-1 lotes\n",
    "            break\n",
    "    hdf5_file.close()\n",
    "    return (training_images, training_labels), (test_images, test_labels)\n",
    "\n",
    "var = extract_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_from_route():\n",
    "    #(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "    (train_images, train_labels),(test_images, test_labels) = extract_dataset()\n",
    "    training_set = (train_images, train_labels)\n",
    "    test_set = (test_images, test_labels)\n",
    "    return training_set, test_set\n",
    "\n",
    "training_set, test_set = load_dataset_from_route()\n",
    "#class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
    "training_images = training_set[0]/255\n",
    "training_labels = training_set[1]\n",
    "test_images = test_set[0]/255\n",
    "test_labels = test_set[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (30, 256, 256, 3) was passed for an output of shape (None, 252, 252, 3) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-46658f149de4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[0mvgg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sgd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mse'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;31m#vgg_model.summary()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m \u001b[0mvgg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;31m#ValueError: A target array with shape (30, 256, 256, 3) was passed for an output of shape (None, 56, 56, 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;31m#while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[0;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2536\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2538\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2540\u001b[0m       \u001b[1;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    741\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[0;32m    742\u001b[0m                            \u001b[1;34m' was passed for an output of shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m                            \u001b[1;34m' while using as loss `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    744\u001b[0m                            \u001b[1;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                            'as the output.')\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (30, 256, 256, 3) was passed for an output of shape (None, 252, 252, 3) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "def create_model(classes):\n",
    "    #model = vgg16.VGG16(include_top=True, weights=None, input_tensor=None, input_shape=(32,32,3), pooling='max', classes=10)\n",
    "    #sequential doesn't seem to work that well because \n",
    "    input_shape = (256,256,3)\n",
    "    #fcn_model = Sequential()\n",
    "    img_input = layers.Input(shape=input_shape)\n",
    "    \n",
    "    #primer bloque Conv -> Conv -> Pooling\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "    \n",
    "    #segundo bloque\n",
    "    x = layers.Conv2D(128, (3, 3),activation='relu',padding='same',name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),activation='relu',padding='same',name='block2_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    \n",
    "    #tercer bloque\n",
    "    x = layers.Conv2D(256, (3, 3),activation='relu',padding='same',name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),activation='relu',padding='same',name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),activation='relu',padding='same',name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    \n",
    "    pool_3 = x\n",
    "    \n",
    "    #cuarto bloque\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    \n",
    "    pool_4 = x\n",
    "    \n",
    "    #5to bloque\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    #Fullyconnected Layer\n",
    "    #x = layers.Flatten(name='flatten')(x)\n",
    "    #x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "    #x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
    "    #x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    #fc_6\n",
    "    x = layers.Conv2D(4096, 7, padding='valid', activation='relu', use_bias=True, name='fc_1')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    #fc_7\n",
    "    x = Conv2D(4096, 1, padding='valid', activation='relu', use_bias=True, name='fc_2')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    encoder_graph = Conv2D(classes, 1, padding='valid', activation='relu', use_bias=True, name='encoder_graph')(x)\n",
    "\n",
    "    # Unpool to 16x\n",
    "    score_2 = layers.Conv2DTranspose(classes, 4, strides=(2, 2), padding='valid')(encoder_graph)\n",
    "    score_pool_4 = layers.Conv2D(classes, 1, padding='valid', use_bias=True)(pool_4)\n",
    "    score_pool_4 = layers.Cropping2D(cropping=5)(score_pool_4)\n",
    "    score_16x_upsampled = Add()([score_2, score_pool_4])\n",
    "        \n",
    "    # Unpool to 8x\n",
    "    score_4 = layers.Conv2DTranspose(classes, 4, strides=(2, 2), padding='valid')(score_16x_upsampled)\n",
    "    score_pool_3 = layers.Conv2D(classes, 1, padding='valid', use_bias=True)(pool_3)\n",
    "    #score_4 = layers.ZeroPadding2D(padding=((1,0), (1, 0)))(score_4)\n",
    "    #print(score_4.shape)\n",
    "    score_pool_3 = layers.Cropping2D(cropping=9)(score_pool_3)\n",
    "    #print(score_pool_3.shape)\n",
    "    score_8x_upsampled = Add()([score_4, score_pool_3])\n",
    "\n",
    "    # Unpool to image shape\n",
    "    upsample = layers.Conv2DTranspose(classes, 16, strides=(22, 22), padding='same')(score_8x_upsampled)        \n",
    "    upsample = layers.Cropping2D(cropping=28)(upsample)\n",
    "    #upsample = layers.Conv2DTranspose(classes, 64, strides=(16,16), padding='same')(upsample)\n",
    "    \n",
    "    output_graph = Activation('softmax')(upsample)\n",
    "\n",
    "    #print(output_graph.shape)\n",
    "    #print(img_input.shape)\n",
    "    \n",
    "    #return output_graph\n",
    "    \n",
    "    fcn_model = Model(img_input, output_graph)\n",
    "    return fcn_model\n",
    "\n",
    "vgg_model = create_model(3)\n",
    "vgg_model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['acc', 'mse'])\n",
    "#vgg_model.summary()\n",
    "vgg_model.fit(x=training_images, y=training_labels,batch_size = 32, epochs = 10, verbose = 1,callbacks = None, validation_split=0.0, validation_data=(test_images,test_labels) )\n",
    "#ValueError: A target array with shape (30, 256, 256, 3) was passed for an output of shape (None, 56, 56, 2) \n",
    "#while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.\n",
    "#Esto se refiere a que output_graph es un arreglo con dimensiones (None, 56, 56,2)\n",
    "\n",
    "vgg_model.save_weights('modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('ElAvion.jpg')\n",
    "image = cv.resize(image, (32,32))\n",
    "plt.imshow(image)\n",
    "image = np.resize(image, (1,32,32,3))\n",
    "#plt.imshow(image)\n",
    "image = tf.cast(image, tf.float32)\n",
    "print(image.shape)\n",
    "prediction = vgg_model.predict(image, batch_size = None, verbose = 0, steps = None, callbacks = None, max_queue_size = 10, workers = 1, use_multiprocessing = False)\n",
    "print(prediction)\n",
    "#predicted = np.argmax(prediction.shape[0], axis=1)\n",
    "#print(class_names[predicted])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
